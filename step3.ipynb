{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    순위    AVG   G   PA   AB   R   H  2B  3B  HR   TB  RBI  SAC  SF\n",
      "0    1  0.390  46  195  177  31  69  10   0   7  100   38    0   3\n",
      "1    2  0.389  45  187  162  33  63  12   0   2   81   27    0   4\n",
      "2    3  0.361  47  214  194  32  70  15   2   7  110   27    0   1\n",
      "3    4  0.340  43  192  162  19  55   8   0   4   75   21    0   0\n",
      "4    5  0.332  49  223  208  38  69  12   0  14  123   46    0   2\n",
      "5    6  0.331  44  179  160  20  53   6   0   6   77   41    0   5\n",
      "6    7  0.328  46  203  186  39  61   6   2  11  104   30    1   2\n",
      "7    8  0.324  47  196  173  35  56   8   0   7   85   31    0   0\n",
      "8    9  0.323  46  191  167  30  54  12   1   3   77   25    0   1\n",
      "9   10  0.322  46  200  180  26  58  10   1   6   88   32    0   4\n",
      "10  11  0.319  48  220  191  37  61  13   0  14  116   38    0   2\n",
      "11  12  0.319  51  222  207  32  66  13   5  10  119   38    1   3\n",
      "12  13  0.314  40  176  159  20  50  11   1   7   84   31    0   1\n",
      "13  14  0.313  41  184  166  30  52   6   1   7   81   29    0   1\n",
      "14  15  0.311  47  212  167  30  52   2   3   2   66   21    1   1\n",
      "15  16  0.311  40  174  161  23  50   8   0   0   58   12    2   1\n",
      "16  17  0.308  50  189  156  21  48   8   1   0   58   26    1   3\n",
      "17  18  0.307  48  209  189  21  58  10   1   4   82   29    0   3\n",
      "18  18  0.307  48  206  189  36  58   8   3   1   75   16    1   1\n",
      "19  20  0.304  47  169  148  19  45   7   2   6   74   29    0   5\n",
      "20  21  0.303  46  183  165  24  50  11   1   3   72   24    1   0\n",
      "21  22  0.301  37  170  143  21  43   7   1   1   55   13    2   1\n",
      "22  23  0.299  49  229  187  37  56  16   0  11  105   34    0   1\n",
      "23  23  0.299  46  210  187  33  56  11   1   9   96   34    0   2\n",
      "24  25  0.298  47  219  208  28  62  10   0   3   81   33    1   2\n",
      "25  26  0.297  47  202  175  29  52   8   1  12   98   33    1   1\n",
      "26  27  0.295  49  208  176  27  52   8   1  10   92   31    0   4\n",
      "27  28  0.295  46  196  173  28  51  13   1   8   90   42    0   2\n",
      "28  29  0.291  48  200  172  23  50   6   0   2   62   27    1   2\n",
      "29  30  0.290  38  162  145  18  42   8   3   4   68   30    0   5\n"
     ]
    }
   ],
   "source": [
    "a = pd.read_excel('./baseball_1.xlsx')\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = a.drop(columns=['순위'], axis = 1).values\n",
    "y_train = a[['순위']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.39 ,  46.   , 195.   , 177.   ,  31.   ,  69.   ,  10.   ,\n",
       "          0.   ,   7.   , 100.   ,  38.   ,   0.   ,   3.   ],\n",
       "       [  0.389,  45.   , 187.   , 162.   ,  33.   ,  63.   ,  12.   ,\n",
       "          0.   ,   2.   ,  81.   ,  27.   ,   0.   ,   4.   ],\n",
       "       [  0.361,  47.   , 214.   , 194.   ,  32.   ,  70.   ,  15.   ,\n",
       "          2.   ,   7.   , 110.   ,  27.   ,   0.   ,   1.   ],\n",
       "       [  0.34 ,  43.   , 192.   , 162.   ,  19.   ,  55.   ,   8.   ,\n",
       "          0.   ,   4.   ,  75.   ,  21.   ,   0.   ,   0.   ],\n",
       "       [  0.332,  49.   , 223.   , 208.   ,  38.   ,  69.   ,  12.   ,\n",
       "          0.   ,  14.   , 123.   ,  46.   ,   0.   ,   2.   ],\n",
       "       [  0.331,  44.   , 179.   , 160.   ,  20.   ,  53.   ,   6.   ,\n",
       "          0.   ,   6.   ,  77.   ,  41.   ,   0.   ,   5.   ],\n",
       "       [  0.328,  46.   , 203.   , 186.   ,  39.   ,  61.   ,   6.   ,\n",
       "          2.   ,  11.   , 104.   ,  30.   ,   1.   ,   2.   ],\n",
       "       [  0.324,  47.   , 196.   , 173.   ,  35.   ,  56.   ,   8.   ,\n",
       "          0.   ,   7.   ,  85.   ,  31.   ,   0.   ,   0.   ],\n",
       "       [  0.323,  46.   , 191.   , 167.   ,  30.   ,  54.   ,  12.   ,\n",
       "          1.   ,   3.   ,  77.   ,  25.   ,   0.   ,   1.   ],\n",
       "       [  0.322,  46.   , 200.   , 180.   ,  26.   ,  58.   ,  10.   ,\n",
       "          1.   ,   6.   ,  88.   ,  32.   ,   0.   ,   4.   ],\n",
       "       [  0.319,  48.   , 220.   , 191.   ,  37.   ,  61.   ,  13.   ,\n",
       "          0.   ,  14.   , 116.   ,  38.   ,   0.   ,   2.   ],\n",
       "       [  0.319,  51.   , 222.   , 207.   ,  32.   ,  66.   ,  13.   ,\n",
       "          5.   ,  10.   , 119.   ,  38.   ,   1.   ,   3.   ],\n",
       "       [  0.314,  40.   , 176.   , 159.   ,  20.   ,  50.   ,  11.   ,\n",
       "          1.   ,   7.   ,  84.   ,  31.   ,   0.   ,   1.   ],\n",
       "       [  0.313,  41.   , 184.   , 166.   ,  30.   ,  52.   ,   6.   ,\n",
       "          1.   ,   7.   ,  81.   ,  29.   ,   0.   ,   1.   ],\n",
       "       [  0.311,  47.   , 212.   , 167.   ,  30.   ,  52.   ,   2.   ,\n",
       "          3.   ,   2.   ,  66.   ,  21.   ,   1.   ,   1.   ],\n",
       "       [  0.311,  40.   , 174.   , 161.   ,  23.   ,  50.   ,   8.   ,\n",
       "          0.   ,   0.   ,  58.   ,  12.   ,   2.   ,   1.   ],\n",
       "       [  0.308,  50.   , 189.   , 156.   ,  21.   ,  48.   ,   8.   ,\n",
       "          1.   ,   0.   ,  58.   ,  26.   ,   1.   ,   3.   ],\n",
       "       [  0.307,  48.   , 209.   , 189.   ,  21.   ,  58.   ,  10.   ,\n",
       "          1.   ,   4.   ,  82.   ,  29.   ,   0.   ,   3.   ],\n",
       "       [  0.307,  48.   , 206.   , 189.   ,  36.   ,  58.   ,   8.   ,\n",
       "          3.   ,   1.   ,  75.   ,  16.   ,   1.   ,   1.   ],\n",
       "       [  0.304,  47.   , 169.   , 148.   ,  19.   ,  45.   ,   7.   ,\n",
       "          2.   ,   6.   ,  74.   ,  29.   ,   0.   ,   5.   ],\n",
       "       [  0.303,  46.   , 183.   , 165.   ,  24.   ,  50.   ,  11.   ,\n",
       "          1.   ,   3.   ,  72.   ,  24.   ,   1.   ,   0.   ],\n",
       "       [  0.301,  37.   , 170.   , 143.   ,  21.   ,  43.   ,   7.   ,\n",
       "          1.   ,   1.   ,  55.   ,  13.   ,   2.   ,   1.   ],\n",
       "       [  0.299,  49.   , 229.   , 187.   ,  37.   ,  56.   ,  16.   ,\n",
       "          0.   ,  11.   , 105.   ,  34.   ,   0.   ,   1.   ],\n",
       "       [  0.299,  46.   , 210.   , 187.   ,  33.   ,  56.   ,  11.   ,\n",
       "          1.   ,   9.   ,  96.   ,  34.   ,   0.   ,   2.   ],\n",
       "       [  0.298,  47.   , 219.   , 208.   ,  28.   ,  62.   ,  10.   ,\n",
       "          0.   ,   3.   ,  81.   ,  33.   ,   1.   ,   2.   ],\n",
       "       [  0.297,  47.   , 202.   , 175.   ,  29.   ,  52.   ,   8.   ,\n",
       "          1.   ,  12.   ,  98.   ,  33.   ,   1.   ,   1.   ],\n",
       "       [  0.295,  49.   , 208.   , 176.   ,  27.   ,  52.   ,   8.   ,\n",
       "          1.   ,  10.   ,  92.   ,  31.   ,   0.   ,   4.   ],\n",
       "       [  0.295,  46.   , 196.   , 173.   ,  28.   ,  51.   ,  13.   ,\n",
       "          1.   ,   8.   ,  90.   ,  42.   ,   0.   ,   2.   ],\n",
       "       [  0.291,  48.   , 200.   , 172.   ,  23.   ,  50.   ,   6.   ,\n",
       "          0.   ,   2.   ,  62.   ,  27.   ,   1.   ,   2.   ],\n",
       "       [  0.29 ,  38.   , 162.   , 145.   ,  18.   ,  42.   ,   8.   ,\n",
       "          3.   ,   4.   ,  68.   ,  30.   ,   0.   ,   5.   ]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 13)\n",
      "(30, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 20 21 22 23 25 26\n",
      " 27 28 29 30]\n",
      "28\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(y_train))\n",
    "print(len(np.unique(y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "\n",
    "class custom_data(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.x[index]\n",
    "        y = self.y[index]\n",
    "\n",
    "        x = torch.tensor(x, dtype = torch.float32)\n",
    "        y = torch.tensor(y, dtype = torch.long)\n",
    "\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = custom_data(x_train, y_train)\n",
    "train_loader = DataLoader(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 13])\n",
      "torch.Size([1, 1])\n",
      "torch.float32\n",
      "torch.int64\n"
     ]
    }
   ],
   "source": [
    "x_in, y_out = next(iter(train_loader))\n",
    "\n",
    "print(x_in.shape)\n",
    "print(y_out.shape)\n",
    "\n",
    "print(x_in.dtype)\n",
    "print(y_out.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mymodel(\n",
      "  (fc1): Linear(in_features=13, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=40, bias=True)\n",
      "  (fc3): Linear(in_features=40, out_features=31, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class Mymodel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Mymodel, self).__init__()\n",
    "        self.fc1 = nn.Linear(13, 50)\n",
    "        self.fc2 = nn.Linear(50, 40)\n",
    "        self.fc3 = nn.Linear(40, 31)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        out = self.fc3(x)\n",
    "        return out\n",
    "    \n",
    "model = Mymodel()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                [-1, 1, 50]             700\n",
      "            Linear-2                [-1, 1, 40]           2,040\n",
      "            Linear-3                [-1, 1, 31]           1,271\n",
      "================================================================\n",
      "Total params: 4,011\n",
      "Trainable params: 4,011\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.02\n",
      "Estimated Total Size (MB): 0.02\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "# 입력의 크기를 넣어줘야 함\n",
    "summary(model, (1, 13), device = 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100, Loss : 2.381150245666504\n",
      "Epoch 200, Loss : 1.3861006498336792\n",
      "Epoch 300, Loss : 1.297465205192566\n",
      "Epoch 400, Loss : 0.9910264015197754\n",
      "Epoch 500, Loss : 0.048543039709329605\n",
      "Epoch 600, Loss : 0.03720228374004364\n",
      "Epoch 700, Loss : 0.03915843367576599\n",
      "Epoch 800, Loss : 0.006207234691828489\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.001)\n",
    "\n",
    "num_epochs = 850\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for x_batch, y_batch in train_loader:\n",
    "        outputs = model(x_batch)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(outputs, y_batch.squeeze(dim=-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if (epoch+1) % 100 == 0:\n",
    "        print(f'Epoch {epoch+1}, Loss : {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    순위    AVG   G   PA   AB   R   H  2B  3B  HR   TB  RBI  SAC  SF\n",
      "0    1  0.390  46  195  177  31  69  10   0   7  100   38    0   3\n",
      "1    2  0.389  45  187  162  33  63  12   0   2   81   27    0   4\n",
      "2    3  0.361  47  214  194  32  70  15   2   7  110   27    0   1\n",
      "3    4  0.340  43  192  162  19  55   8   0   4   75   21    0   0\n",
      "4    5  0.332  49  223  208  38  69  12   0  14  123   46    0   2\n",
      "5    6  0.331  44  179  160  20  53   6   0   6   77   41    0   5\n",
      "6    7  0.328  46  203  186  39  61   6   2  11  104   30    1   2\n",
      "7    8  0.324  47  196  173  35  56   8   0   7   85   31    0   0\n",
      "8    9  0.323  46  191  167  30  54  12   1   3   77   25    0   1\n",
      "9   10  0.322  46  200  180  26  58  10   1   6   88   32    0   4\n",
      "10  11  0.319  48  220  191  37  61  13   0  14  116   38    0   2\n",
      "11  12  0.319  51  222  207  32  66  13   5  10  119   38    1   3\n",
      "12  13  0.314  40  176  159  20  50  11   1   7   84   31    0   1\n",
      "13  14  0.313  41  184  166  30  52   6   1   7   81   29    0   1\n",
      "14  15  0.311  47  212  167  30  52   2   3   2   66   21    1   1\n",
      "15  16  0.311  40  174  161  23  50   8   0   0   58   12    2   1\n",
      "16  17  0.308  50  189  156  21  48   8   1   0   58   26    1   3\n",
      "17  18  0.307  48  209  189  21  58  10   1   4   82   29    0   3\n",
      "18  18  0.307  48  206  189  36  58   8   3   1   75   16    1   1\n",
      "19  20  0.304  47  169  148  19  45   7   2   6   74   29    0   5\n",
      "20  21  0.303  46  183  165  24  50  11   1   3   72   24    1   0\n",
      "21  22  0.301  37  170  143  21  43   7   1   1   55   13    2   1\n",
      "22  23  0.299  49  229  187  37  56  16   0  11  105   34    0   1\n",
      "23  23  0.299  46  210  187  33  56  11   1   9   96   34    0   2\n",
      "24  25  0.298  47  219  208  28  62  10   0   3   81   33    1   2\n",
      "25  26  0.297  47  202  175  29  52   8   1  12   98   33    1   1\n",
      "26  27  0.295  49  208  176  27  52   8   1  10   92   31    0   4\n",
      "27  28  0.295  46  196  173  28  51  13   1   8   90   42    0   2\n",
      "28  29  0.291  48  200  172  23  50   6   0   2   62   27    1   2\n",
      "29  30  0.290  38  162  145  18  42   8   3   4   68   30    0   5\n"
     ]
    }
   ],
   "source": [
    "b = pd.read_excel('./baseball_1.xlsx')\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = b.drop(columns=['순위'], axis = 1).values\n",
    "y_test = b[['순위']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.39   46.    195.    177.     31.     69.     10.      0.      7.\n",
      "  100.     38.      0.      3.   ]\n",
      " [  0.389  45.    187.    162.     33.     63.     12.      0.      2.\n",
      "   81.     27.      0.      4.   ]\n",
      " [  0.361  47.    214.    194.     32.     70.     15.      2.      7.\n",
      "  110.     27.      0.      1.   ]\n",
      " [  0.34   43.    192.    162.     19.     55.      8.      0.      4.\n",
      "   75.     21.      0.      0.   ]\n",
      " [  0.332  49.    223.    208.     38.     69.     12.      0.     14.\n",
      "  123.     46.      0.      2.   ]\n",
      " [  0.331  44.    179.    160.     20.     53.      6.      0.      6.\n",
      "   77.     41.      0.      5.   ]\n",
      " [  0.328  46.    203.    186.     39.     61.      6.      2.     11.\n",
      "  104.     30.      1.      2.   ]\n",
      " [  0.324  47.    196.    173.     35.     56.      8.      0.      7.\n",
      "   85.     31.      0.      0.   ]\n",
      " [  0.323  46.    191.    167.     30.     54.     12.      1.      3.\n",
      "   77.     25.      0.      1.   ]\n",
      " [  0.322  46.    200.    180.     26.     58.     10.      1.      6.\n",
      "   88.     32.      0.      4.   ]\n",
      " [  0.319  48.    220.    191.     37.     61.     13.      0.     14.\n",
      "  116.     38.      0.      2.   ]\n",
      " [  0.319  51.    222.    207.     32.     66.     13.      5.     10.\n",
      "  119.     38.      1.      3.   ]\n",
      " [  0.314  40.    176.    159.     20.     50.     11.      1.      7.\n",
      "   84.     31.      0.      1.   ]\n",
      " [  0.313  41.    184.    166.     30.     52.      6.      1.      7.\n",
      "   81.     29.      0.      1.   ]\n",
      " [  0.311  47.    212.    167.     30.     52.      2.      3.      2.\n",
      "   66.     21.      1.      1.   ]\n",
      " [  0.311  40.    174.    161.     23.     50.      8.      0.      0.\n",
      "   58.     12.      2.      1.   ]\n",
      " [  0.308  50.    189.    156.     21.     48.      8.      1.      0.\n",
      "   58.     26.      1.      3.   ]\n",
      " [  0.307  48.    209.    189.     21.     58.     10.      1.      4.\n",
      "   82.     29.      0.      3.   ]\n",
      " [  0.307  48.    206.    189.     36.     58.      8.      3.      1.\n",
      "   75.     16.      1.      1.   ]\n",
      " [  0.304  47.    169.    148.     19.     45.      7.      2.      6.\n",
      "   74.     29.      0.      5.   ]\n",
      " [  0.303  46.    183.    165.     24.     50.     11.      1.      3.\n",
      "   72.     24.      1.      0.   ]\n",
      " [  0.301  37.    170.    143.     21.     43.      7.      1.      1.\n",
      "   55.     13.      2.      1.   ]\n",
      " [  0.299  49.    229.    187.     37.     56.     16.      0.     11.\n",
      "  105.     34.      0.      1.   ]\n",
      " [  0.299  46.    210.    187.     33.     56.     11.      1.      9.\n",
      "   96.     34.      0.      2.   ]\n",
      " [  0.298  47.    219.    208.     28.     62.     10.      0.      3.\n",
      "   81.     33.      1.      2.   ]\n",
      " [  0.297  47.    202.    175.     29.     52.      8.      1.     12.\n",
      "   98.     33.      1.      1.   ]\n",
      " [  0.295  49.    208.    176.     27.     52.      8.      1.     10.\n",
      "   92.     31.      0.      4.   ]\n",
      " [  0.295  46.    196.    173.     28.     51.     13.      1.      8.\n",
      "   90.     42.      0.      2.   ]\n",
      " [  0.291  48.    200.    172.     23.     50.      6.      0.      2.\n",
      "   62.     27.      1.      2.   ]\n",
      " [  0.29   38.    162.    145.     18.     42.      8.      3.      4.\n",
      "   68.     30.      0.      5.   ]]\n",
      "[[ 1]\n",
      " [ 2]\n",
      " [ 3]\n",
      " [ 4]\n",
      " [ 5]\n",
      " [ 6]\n",
      " [ 7]\n",
      " [ 8]\n",
      " [ 9]\n",
      " [10]\n",
      " [11]\n",
      " [12]\n",
      " [13]\n",
      " [14]\n",
      " [15]\n",
      " [16]\n",
      " [17]\n",
      " [18]\n",
      " [18]\n",
      " [20]\n",
      " [21]\n",
      " [22]\n",
      " [23]\n",
      " [23]\n",
      " [25]\n",
      " [26]\n",
      " [27]\n",
      " [28]\n",
      " [29]\n",
      " [30]]\n"
     ]
    }
   ],
   "source": [
    "print(x_test)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = custom_data(x_test, y_test)\n",
    "test_loader = DataLoader(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 90.0%, Pred : tensor([17.6739])\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for x_batch, y_batch in test_loader:\n",
    "        outputs = model(x_batch)\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += y_batch.size(0)\n",
    "        correct += (predicted == y_batch).sum().item()\n",
    "\n",
    "print(f'Accuracy : {100 * correct / total}%, Pred : {_}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
