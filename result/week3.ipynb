{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class XOR_gate(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(XOR_gate, self).__init__()\n",
    "        self.l1 = nn.Linear(2,8)\n",
    "        self.l2 = nn.Linear(8,4)\n",
    "        self.l3 = nn.Linear(4,1)\n",
    "        self.activation = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.l1(x)\n",
    "        out = self.activation(out)\n",
    "        out = self.l2(out)\n",
    "        out = self.activation(out)\n",
    "        out = self.l3(out)\n",
    "        out = self.activation(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "model = XOR_gate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/20000], Loss: 0.2500\n",
      "Epoch [200/20000], Loss: 0.2500\n",
      "Epoch [300/20000], Loss: 0.2500\n",
      "Epoch [400/20000], Loss: 0.2500\n",
      "Epoch [500/20000], Loss: 0.2499\n",
      "Epoch [600/20000], Loss: 0.2499\n",
      "Epoch [700/20000], Loss: 0.2499\n",
      "Epoch [800/20000], Loss: 0.2499\n",
      "Epoch [900/20000], Loss: 0.2499\n",
      "Epoch [1000/20000], Loss: 0.2499\n",
      "Epoch [1100/20000], Loss: 0.2499\n",
      "Epoch [1200/20000], Loss: 0.2499\n",
      "Epoch [1300/20000], Loss: 0.2499\n",
      "Epoch [1400/20000], Loss: 0.2499\n",
      "Epoch [1500/20000], Loss: 0.2499\n",
      "Epoch [1600/20000], Loss: 0.2499\n",
      "Epoch [1700/20000], Loss: 0.2499\n",
      "Epoch [1800/20000], Loss: 0.2499\n",
      "Epoch [1900/20000], Loss: 0.2499\n",
      "Epoch [2000/20000], Loss: 0.2499\n",
      "Epoch [2100/20000], Loss: 0.2499\n",
      "Epoch [2200/20000], Loss: 0.2499\n",
      "Epoch [2300/20000], Loss: 0.2499\n",
      "Epoch [2400/20000], Loss: 0.2499\n",
      "Epoch [2500/20000], Loss: 0.2499\n",
      "Epoch [2600/20000], Loss: 0.2499\n",
      "Epoch [2700/20000], Loss: 0.2499\n",
      "Epoch [2800/20000], Loss: 0.2499\n",
      "Epoch [2900/20000], Loss: 0.2499\n",
      "Epoch [3000/20000], Loss: 0.2499\n",
      "Epoch [3100/20000], Loss: 0.2499\n",
      "Epoch [3200/20000], Loss: 0.2499\n",
      "Epoch [3300/20000], Loss: 0.2499\n",
      "Epoch [3400/20000], Loss: 0.2499\n",
      "Epoch [3500/20000], Loss: 0.2499\n",
      "Epoch [3600/20000], Loss: 0.2499\n",
      "Epoch [3700/20000], Loss: 0.2498\n",
      "Epoch [3800/20000], Loss: 0.2498\n",
      "Epoch [3900/20000], Loss: 0.2498\n",
      "Epoch [4000/20000], Loss: 0.2498\n",
      "Epoch [4100/20000], Loss: 0.2498\n",
      "Epoch [4200/20000], Loss: 0.2498\n",
      "Epoch [4300/20000], Loss: 0.2498\n",
      "Epoch [4400/20000], Loss: 0.2498\n",
      "Epoch [4500/20000], Loss: 0.2498\n",
      "Epoch [4600/20000], Loss: 0.2498\n",
      "Epoch [4700/20000], Loss: 0.2498\n",
      "Epoch [4800/20000], Loss: 0.2498\n",
      "Epoch [4900/20000], Loss: 0.2498\n",
      "Epoch [5000/20000], Loss: 0.2498\n",
      "Epoch [5100/20000], Loss: 0.2498\n",
      "Epoch [5200/20000], Loss: 0.2498\n",
      "Epoch [5300/20000], Loss: 0.2498\n",
      "Epoch [5400/20000], Loss: 0.2498\n",
      "Epoch [5500/20000], Loss: 0.2498\n",
      "Epoch [5600/20000], Loss: 0.2498\n",
      "Epoch [5700/20000], Loss: 0.2497\n",
      "Epoch [5800/20000], Loss: 0.2497\n",
      "Epoch [5900/20000], Loss: 0.2497\n",
      "Epoch [6000/20000], Loss: 0.2497\n",
      "Epoch [6100/20000], Loss: 0.2497\n",
      "Epoch [6200/20000], Loss: 0.2497\n",
      "Epoch [6300/20000], Loss: 0.2497\n",
      "Epoch [6400/20000], Loss: 0.2497\n",
      "Epoch [6500/20000], Loss: 0.2497\n",
      "Epoch [6600/20000], Loss: 0.2497\n",
      "Epoch [6700/20000], Loss: 0.2497\n",
      "Epoch [6800/20000], Loss: 0.2497\n",
      "Epoch [6900/20000], Loss: 0.2497\n",
      "Epoch [7000/20000], Loss: 0.2496\n",
      "Epoch [7100/20000], Loss: 0.2496\n",
      "Epoch [7200/20000], Loss: 0.2496\n",
      "Epoch [7300/20000], Loss: 0.2496\n",
      "Epoch [7400/20000], Loss: 0.2496\n",
      "Epoch [7500/20000], Loss: 0.2496\n",
      "Epoch [7600/20000], Loss: 0.2496\n",
      "Epoch [7700/20000], Loss: 0.2496\n",
      "Epoch [7800/20000], Loss: 0.2496\n",
      "Epoch [7900/20000], Loss: 0.2495\n",
      "Epoch [8000/20000], Loss: 0.2495\n",
      "Epoch [8100/20000], Loss: 0.2495\n",
      "Epoch [8200/20000], Loss: 0.2495\n",
      "Epoch [8300/20000], Loss: 0.2495\n",
      "Epoch [8400/20000], Loss: 0.2495\n",
      "Epoch [8500/20000], Loss: 0.2495\n",
      "Epoch [8600/20000], Loss: 0.2494\n",
      "Epoch [8700/20000], Loss: 0.2494\n",
      "Epoch [8800/20000], Loss: 0.2494\n",
      "Epoch [8900/20000], Loss: 0.2494\n",
      "Epoch [9000/20000], Loss: 0.2494\n",
      "Epoch [9100/20000], Loss: 0.2493\n",
      "Epoch [9200/20000], Loss: 0.2493\n",
      "Epoch [9300/20000], Loss: 0.2493\n",
      "Epoch [9400/20000], Loss: 0.2493\n",
      "Epoch [9500/20000], Loss: 0.2493\n",
      "Epoch [9600/20000], Loss: 0.2492\n",
      "Epoch [9700/20000], Loss: 0.2492\n",
      "Epoch [9800/20000], Loss: 0.2492\n",
      "Epoch [9900/20000], Loss: 0.2492\n",
      "Epoch [10000/20000], Loss: 0.2491\n",
      "Epoch [10100/20000], Loss: 0.2491\n",
      "Epoch [10200/20000], Loss: 0.2491\n",
      "Epoch [10300/20000], Loss: 0.2490\n",
      "Epoch [10400/20000], Loss: 0.2490\n",
      "Epoch [10500/20000], Loss: 0.2490\n",
      "Epoch [10600/20000], Loss: 0.2489\n",
      "Epoch [10700/20000], Loss: 0.2489\n",
      "Epoch [10800/20000], Loss: 0.2488\n",
      "Epoch [10900/20000], Loss: 0.2488\n",
      "Epoch [11000/20000], Loss: 0.2487\n",
      "Epoch [11100/20000], Loss: 0.2487\n",
      "Epoch [11200/20000], Loss: 0.2486\n",
      "Epoch [11300/20000], Loss: 0.2486\n",
      "Epoch [11400/20000], Loss: 0.2485\n",
      "Epoch [11500/20000], Loss: 0.2484\n",
      "Epoch [11600/20000], Loss: 0.2484\n",
      "Epoch [11700/20000], Loss: 0.2483\n",
      "Epoch [11800/20000], Loss: 0.2482\n",
      "Epoch [11900/20000], Loss: 0.2481\n",
      "Epoch [12000/20000], Loss: 0.2481\n",
      "Epoch [12100/20000], Loss: 0.2480\n",
      "Epoch [12200/20000], Loss: 0.2479\n",
      "Epoch [12300/20000], Loss: 0.2478\n",
      "Epoch [12400/20000], Loss: 0.2477\n",
      "Epoch [12500/20000], Loss: 0.2475\n",
      "Epoch [12600/20000], Loss: 0.2474\n",
      "Epoch [12700/20000], Loss: 0.2473\n",
      "Epoch [12800/20000], Loss: 0.2471\n",
      "Epoch [12900/20000], Loss: 0.2470\n",
      "Epoch [13000/20000], Loss: 0.2468\n",
      "Epoch [13100/20000], Loss: 0.2466\n",
      "Epoch [13200/20000], Loss: 0.2464\n",
      "Epoch [13300/20000], Loss: 0.2462\n",
      "Epoch [13400/20000], Loss: 0.2460\n",
      "Epoch [13500/20000], Loss: 0.2457\n",
      "Epoch [13600/20000], Loss: 0.2455\n",
      "Epoch [13700/20000], Loss: 0.2452\n",
      "Epoch [13800/20000], Loss: 0.2449\n",
      "Epoch [13900/20000], Loss: 0.2446\n",
      "Epoch [14000/20000], Loss: 0.2442\n",
      "Epoch [14100/20000], Loss: 0.2438\n",
      "Epoch [14200/20000], Loss: 0.2434\n",
      "Epoch [14300/20000], Loss: 0.2429\n",
      "Epoch [14400/20000], Loss: 0.2424\n",
      "Epoch [14500/20000], Loss: 0.2418\n",
      "Epoch [14600/20000], Loss: 0.2412\n",
      "Epoch [14700/20000], Loss: 0.2406\n",
      "Epoch [14800/20000], Loss: 0.2399\n",
      "Epoch [14900/20000], Loss: 0.2391\n",
      "Epoch [15000/20000], Loss: 0.2382\n",
      "Epoch [15100/20000], Loss: 0.2373\n",
      "Epoch [15200/20000], Loss: 0.2363\n",
      "Epoch [15300/20000], Loss: 0.2352\n",
      "Epoch [15400/20000], Loss: 0.2340\n",
      "Epoch [15500/20000], Loss: 0.2327\n",
      "Epoch [15600/20000], Loss: 0.2314\n",
      "Epoch [15700/20000], Loss: 0.2299\n",
      "Epoch [15800/20000], Loss: 0.2283\n",
      "Epoch [15900/20000], Loss: 0.2266\n",
      "Epoch [16000/20000], Loss: 0.2248\n",
      "Epoch [16100/20000], Loss: 0.2229\n",
      "Epoch [16200/20000], Loss: 0.2209\n",
      "Epoch [16300/20000], Loss: 0.2187\n",
      "Epoch [16400/20000], Loss: 0.2165\n",
      "Epoch [16500/20000], Loss: 0.2143\n",
      "Epoch [16600/20000], Loss: 0.2119\n",
      "Epoch [16700/20000], Loss: 0.2095\n",
      "Epoch [16800/20000], Loss: 0.2071\n",
      "Epoch [16900/20000], Loss: 0.2046\n",
      "Epoch [17000/20000], Loss: 0.2022\n",
      "Epoch [17100/20000], Loss: 0.1997\n",
      "Epoch [17200/20000], Loss: 0.1972\n",
      "Epoch [17300/20000], Loss: 0.1947\n",
      "Epoch [17400/20000], Loss: 0.1923\n",
      "Epoch [17500/20000], Loss: 0.1899\n",
      "Epoch [17600/20000], Loss: 0.1874\n",
      "Epoch [17700/20000], Loss: 0.1851\n",
      "Epoch [17800/20000], Loss: 0.1827\n",
      "Epoch [17900/20000], Loss: 0.1803\n",
      "Epoch [18000/20000], Loss: 0.1779\n",
      "Epoch [18100/20000], Loss: 0.1755\n",
      "Epoch [18200/20000], Loss: 0.1730\n",
      "Epoch [18300/20000], Loss: 0.1704\n",
      "Epoch [18400/20000], Loss: 0.1677\n",
      "Epoch [18500/20000], Loss: 0.1648\n",
      "Epoch [18600/20000], Loss: 0.1617\n",
      "Epoch [18700/20000], Loss: 0.1581\n",
      "Epoch [18800/20000], Loss: 0.1541\n",
      "Epoch [18900/20000], Loss: 0.1494\n",
      "Epoch [19000/20000], Loss: 0.1439\n",
      "Epoch [19100/20000], Loss: 0.1373\n",
      "Epoch [19200/20000], Loss: 0.1294\n",
      "Epoch [19300/20000], Loss: 0.1203\n",
      "Epoch [19400/20000], Loss: 0.1100\n",
      "Epoch [19500/20000], Loss: 0.0989\n",
      "Epoch [19600/20000], Loss: 0.0876\n",
      "Epoch [19700/20000], Loss: 0.0767\n",
      "Epoch [19800/20000], Loss: 0.0666\n",
      "Epoch [19900/20000], Loss: 0.0577\n",
      "Epoch [20000/20000], Loss: 0.0499\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "x = np.array([[0, 0],\n",
    "              [0, 1],\n",
    "              [1, 0],\n",
    "              [1, 1]])\n",
    "y = np.array([0, 1, 1, 0])\n",
    "\n",
    "x_t = torch.FloatTensor(x).view(x.shape[0], -1)\n",
    "y_t = torch.FloatTensor(y).view(y.shape[0], 1)\n",
    "\n",
    "num_epochs = 20000\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    outputs = model(x_t)\n",
    "    loss = criterion(outputs, y_t)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch+1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
